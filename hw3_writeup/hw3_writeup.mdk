Title         : DATA 621 - Homework 3
Author        : Honey Berk, Ken Markus
Logo          : False
Title Note  : &date;

[TITLE]
   
# Data Exploration

**Dataset**
{ font-size: 120%; }

The dataset under analysis this week contains information on crime for various neighborhoods of a major city. The Training dataset contains 466 observations of 14 variables. The response variable, target, is a categorical variable that denotes whether the crime rate is above the median crime rate (1) or not (0) for that neighborhood. There is one categorical predictor variable, chas, and 12 continuous predictor variables. Following is a short description of each of the 14 variables.

~ Center

|Name    | Definition                                                                         |
|:-------+:-----------------------------------------------------------------------------------|
|zn      |proportion of residential land zoned for large lots (predictor)                     |
|indus   |proportion of non-retail business acres per suburb (predictor)                      |
|chas    |a dummy variable for whether the suburb borders the Charles River (predictor)       |
|nox     |nitrogen oxides concentration (parts per 10 million) (predictor)                    |
|rm      |average number of rooms per dwelling (predictor)                                    |
|age     |proportion of owner-occupied units built prior to 1940 (predictor)                  |
|dis     |weighted mean of distances to five Boston employment centers (predictor)            |
|rad     |index of accessibility to radial highways (predictor)                               |
|tax     |full-value property-tax rate per \$10,000 (predictor)                               |
|ptratio |pupil-teacher ratio by town (predictor)                                             |
|black   |$1000(B_{k}-0.63)^{2}$ where $B_{k}$ is the proportion of blacks by town (predictor)|
|lstat   |lower status of the population (percent) (predictor)                                |
|medv    |median value of owner-occupied homes in \$1000s (predictor)                         |
|target  |whether the crime rate is above the median crime rate (1) or not (0) (response)     |
|----|----|
~
An initial look at the data confirmed that the response variable, target, and the predictor chas were categorical. It also pointed to some large differences in the scale of some of the variables, particularly tax, black and age.

~ Center
![0-summary]

[0-summary]: images/0-summary.PNG "0-summary" { width:auto; max-width:90% }

~
An initial review of the dataset revealed that there were no missing values (NAs).



Boxplots were then generated to examine the distributions of each of the variables.

![1-boxplots]

[1-boxplots]: images/1-boxplots.PNG "1-boxplots" { width:auto; max-width:90% }



**Summary Statistics**
{ font-size: 120%; }

Summary statistics were generated for the dataset:





A correlation matrix generated for the dataset:

~Center
![2-corr]

[2-corr]: images/2-corr.PNG "2-corr" { width:auto; max-width:90% }

~

High correlations were found between the response variable and a number of the predictor variables: nox (0.857), dis (-0.771), rad (0.738), age (0.720), tax (0.699), zn (-0.681), indus (-0.666) and black (-0.610). 

There was also a high degree of correlation indicated between some of the predictor variables, such as rad-tax, nox-indus, nox-dis and lstat-medv. This points to the potential for multicollinearity in any models that include these and other highly-correlated predictors. We will see if this is, indeed, the case when the models are generated. 




# Models


## Backwards, Using Highly-Correlated Predictors

The first model was generated with the eight predictors that were found to be highly-correlated with the response variable (see above): _nox_, _dis_, _age_, _rad_, _tax_, _zn_, _indus_ and _black_. The first iteration found all but one of these predictors, _indus_, to be significant. The model was then re-run with the seven significant predictors:

~ Center
![7-fit.2a]

[7-fit.2a]: images/7-fit.2a.PNG "7-fit.2a" { width:auto; max-width:100% }
~

The resulting equation is as follows:

~ Math
target = -19.324142 + 36.432373*nox + 0.412916*dis + 0.715959*rad + 0.019555*age - 0.009145*tax - 0.064598*zn -0.009862*black
~

The following table summarizes selected analytics:

|Residual|AIC   |BIC       |AUC|McFadden's|
|Deviance|      |          |   |Pseudo $R^{2}$|
+-------:+-------:+-----:+---------:+--:+---:+
| 207.71 |223.7056| 256.8591 |   |0.6784125|

##All Subsets

The leaps package was used to generate the second model, using the all subsets method. All 13 variables were considered with the _regsubsets_ command. Using Mallow's Cp, the optimal number of variables for the model was determined to be five. The following two plots were generated to illustrate this process.

![4-mallowscp]

[4-mallowscp]: images/4-mallowscp.PNG "4-mallowscp" { width:auto; max-width:100% }

![5-mallowscp2]

[5-mallowscp2]: images/5-mallowscp2.PNG "5-mallowscp2" { width:auto; max-width:90% }

The predictors chosen for this model were: nox, age, rad, ptratio and medv. The _glm_ function was then used to generate this model, resulting in the following equation:

~ Math
target = -24.936540 + 25.334778*nox + 0.019403*age + 0.512600*rad + 0.274193*ptratio + 0.085445*medv
~

Summary statistics showed all of the predictors to be significant:

~Center
![6-fit.1]

[6-fit.1]: images/6-fit.1.PNG "6-fit.1" { width:auto; max-width:100% }
~

The following table summarizes selected analytics:

| |Residual|AIC   |BIC       |AUC|McFadden's|
|       |Deviance|      |          |   |Pseudo $R^{2}$|
+-------:+-------:+-----:+---------:+--:+---+
| | 224.71 |236.7103| 261.5754 |   | 0.6520844 |


## glmulti Package

The third model was derived using the glmulti package, which finds the best models (the confidence set of models) among all possible models
(the candidate set, as specified by the user). For this exercise, models were fitted with the glm function and ranked with the AIC criterion; the best models in this case were found through exhaustive screening of the candidates.
