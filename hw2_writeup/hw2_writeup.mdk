Title         : DATA 621 - Homework 2
Author        : Honey Berk, Sanjiv Kumar, Ken Markus
Logo          : False
Title Note  : &date;

[TITLE]

# Confusion Matrix { - }
Using the predicted (scored.class) and actual (class) data from the classification data, the following confusion matrix was generated:
~ Center
| |0  |1          |
+-------------:+---------:+---------:+
|0|119       |30        |
|1|5         |27        |
~
In this confusion matrix, the predicted data is in rows, while the actual data is in columns. The following matrix depicts the meaning of this confusion matrix:
~ Center
| |Actual - Negative  |Actual - Positive          |
+-------------:+---------:+---------:+
|Predicted - Negative|True Negative (TN)       |False Negative (FN)       |
|Predicted - Positive|False Positive (FP)         |True Positive (TP)   |
~

# Functions for Calculated Rates { - }
## Accuracy { - }
~ Math
Accuracy = \frac{TP + TN}{TP + FP + TN + FN}
~
Specifies how often the classifier is correct.

**R Code:**
``` { .pretty }
  # accuracy
  accuracy.fn <- function(df, actual, predicted) {
  confusion <- table(predicted, actual)
  accuracy <- (confusion[2,2] + confusion [1,1]) / sum(confusion)
  return(accuracy)
}
```
  
## Classification Error Rate { - }
~ Math
Classification Error Rate = \frac{FP + FN}{TP + FP + TN + FN}
~
Specifies how often the classifier is wrong.

**R Code:**
``` { .pretty }
  # classification error rate
  error_rate.fn <- function(df, actual, predicted) {
  confusion <- table(predicted, actual)
  error_rate <- (confusion[2,1] + confusion [1,2]) / sum(confusion)
  return(error_rate)
}
```
