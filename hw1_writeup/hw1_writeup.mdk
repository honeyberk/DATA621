Title         : DATA 621 - Homework 1
Author        : Honey Berk, Ken Markus, Sanjiv Kumar, Musa Ganiyu
Logo          : False
Title Note  : &date;

[TITLE]
   
# Data Exploration

The Training dataset contains 2,276 observations of 17 variables, one of which is an index. The other 16 variables are integer types.

**Original Data**
{font-size: 100%}
~ Center
|Variable Name   | Definition             | Theoretical |New Variable        |
|                |                        | Effect      |Name                |
|:---------------|:-----------------------|:-------------------|:---------------|
|INDEX           |Identification Variable)|None                |index           |
|TARGET_WINS     | Number of wins         |N/A                 |wins            |
|TEAM_BATTING_H  | Base hits by batters   |Positive            |base_hits       |
|TEAM_BATTING_2B |Doubles by batters      |Positive            |doubles         |
|TEAM_BATTING_3B |Triples by batters      |Positive            |triples         |
|TEAM_BATTING_HR |Homeruns by batters|Positive            |homeruns        |
|TEAM_BATTING_BB |Walks by batters        |Positive            |walks           |
|TEAM_BATTING_HBP|Batters hit by pitch    |Positive            |N/A             |
|TEAM_BATTING_SO |Strikeouts by batters   |Negative            |b_strikeouts    |
|TEAM_BASERUN_SB |Stolen bases            |Positive            |stolen_bases    |
|TEAM_BASERUN_CS |Caught stealing         |Negative            |N/A             |
|TEAM_FIELDING_E |Errors                  |Negative            |errors          |
|TEAM_FIELDING_DP|Double Plays            |Positive            |double_plays    |
|TEAM_PITCHING_BB|Walks allowed           |Negative            |walks_allowed   |
|TEAM_PITCHING_H |Hits allowed            |Negative            |hits_allowed    |
|TEAM_PITCHING_HR|Homeruns allowed        |Negative            |homeruns_allowed|
|TEAM_PITCHING_SO|Strikeouts by pitchers  |Positive            |p_strikeouts    |
{ font-size:85%; max-width:95%;} 
~

Summary statistics for the training data revealed issues with a number of variables, based upon an initial examination of min., max., median, mean, the number of missing values (NAs) and a few other factors. A cleaning procedure was undertaken to address these issues, during which the data was also checked for collinearity and for outlier data. Ulitmately, the cleaning process included either removing a variable from the dataset or imputing missing data where the variable was deemed critical to the analysis; and then another procedure for handling outliers. (See Data Cleaning section, below, for details.)

**Summary Statistics - Original Data**

~ Center

![describe_train-1]

[describe_train-1]: images/describe_train-1.PNG "describe_train-1" { width:auto; max-width:100%; }
~
# Data Preparation

**Data Cleaning**

Following is a summary of steps that were undertaken to clean the training dataset:

1. Deleted index variable, as it was used only as an identification variable.

1. Added singles hit by batters (singles) variable (see Additional Variables section, below). 
1. Deleted hit_by_pitch (2,085 NAs) and caught_stealing (772 NAs) variables, as they contained too many NAs to fill without significant effect.
1. Used mice and VIM packages to analyze missing data, found a total of 621 NAs over 4 different variables (4.5%-12.5% of data); assumption that the missing data was random (MCAR). Used mice package to impute missing data, using predictive mean matching (PMM) method; then brought imputed data into dataset. 
**Note: **PMM is described in the mice pacakge documentation as being based on work by Donald B. Rubin, Harvard Univeristy (Rubin 1987, p. 168, formulas a and b).[^fn]. Compared with imputation methods based on the normal distribution, PMM is said to produces imputed values that are much more like real values. That means that if the original variable is skewed, the imputed values will also be skewed; if the original values are discrete, the imputed values will also be discrete; etc. That’s because the imputed values are, in essence, real values that are “borrowed” from the real data.
[^fn]: Rubin, D.B. (1987). Multiple imputation for nonresponse in surveys. New York: Wiley.
1. Boxplots were then generated with the imputed data set to check for outliers.
 
![boxplot_ctrain_outlier_ck-4]
[boxplot_ctrain_outlier_ck-4]: images/boxplot_ctrain_outlier_ck-4.PNG "boxplot_ctrain_outlier_ck-4" { width:auto; max-width:100% }
Examined variables with outliers: singles, hits_allowed, errors, stolen_bases, p_strikeouts, walks_allowed, base_hits), converted outliers to NA values. This procedure included:
  * Generating a qqnorm plot, histogram and scatterplot for each variable
  * Using boxplot.stats function to identify outlier values
  * Recoding outlier values as NA
  * Rechecking qqnorm and histogram plots to check for normal distribution
  * Checking skewness and kurtosis to check for significant improvement

**Summary Statistics - Clean Data**

At this point, there were 2,276 observations of 15 variables. Following are summary statistics for the cleaned dataset:
~ Center
![describe_ftrain-5]

[describe_ftrain-5]: images/describe_ftrain-5.PNG "describe_ftrain-5" { width:auto; max-width:100% }
~
As evidenced by the tables, skewness, kurtosis and standard error were significantly improved for all cleaned variables. As a further review of the cleaned data, qqnorm plots were generated for a few variables to compare original to cleaned data.
~ Center
![qqnorm_cleaned-6]

[qqnorm_cleaned-6]: images/qqnorm_cleaned-6.PNG "qqnorm_cleaned-6" { width:auto; max-width:90% }
~
At the completion of the cleaning process, a new csv file was generated for the team to begin the modeling phase.
 
# Models

**Model 1**

Before the first model was generated, a correlation matrix was generated with the cleaned dataset, and some quick regression analyses were generated between certain suspect variables to confirm potential collinearity. Out of the four sets examined, two scenarios were deemed to have high potential for collinearity: base_hits was regressed against singles, doubles, triples and homeruns, with a resulting Adjusted R^2^ of 0.9943, was expected because base_hits is an aggregate variable; and homeruns was regressed against homeruns_allowed, resulting in an R^2^ of 0.9397.



**Model 2**

For the second model, the cleaned data file was loaded and a backwards regression approach was then used to find the optimal model. All of the variables in the dataset were used with the exception of base_hits, as it was a composite of the individual hits variables (see explanation in Model 1 section). The first attempt, model 2a, yielded an Adjusted R^2^ of 0.3979 with six variables with high p-values (so not significant), and an F-statistic of 116.7 on 13 and 2262 DF. For model 2b, homeruns_allowed was removed, yielding an improved R^2^ of 0.3982 and four variables with high p-values. 






A simple approach to identify collinearity among explanatory variables is the use of variance inflation factors (VIF). VIF calculations are straightforward and easily comprehensible; the higher the value, the higher the collinearity. 

(https://beckmw.wordpress.com/2013/02/05/collinearity-and-stepwise-vif-selection/)
